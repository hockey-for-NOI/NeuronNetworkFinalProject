\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2016
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2016}

%\usepackage{nips_2016}

% to compile a camera-ready version, add the [final] option, e.g.:
\usepackage[final]{Project_Proposal}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{CJKutf8}

\begin{CJK*}{UTF8}{gbsn}
\title{《人工神经网络》大作业开题报告}


% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
  刘熙航 \\
  计算机科学与技术系 \\
  清华大学 \\
  \texttt{liuxh15@mails.tsinghua.edu.cn} \\
  %% examples of more authors
  \And
  何琦\\
  计算机科学与技术系 \\
  清华大学 \\
  \texttt{hq15@mails.tsinghua.edu.cn} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}

\begin{document}

\maketitle



\section{任务定义}
\subsection{任务背景}

与传统任务已有固定数据集的情况不同，在真实的场景里，数据是不断产生的，而数据的质量也会随着时间不断变化。甚至，为了获得更好的效果，数据的标注也会不断发生改变。如下面两种场合：

\begin{itemize}
    \item 在自动驾驶的数据标注中，需要判断人被车辆遮挡的情况，在一开始，数据标注所采用的label为“标注员所认为的人全身的位置”。然而在一段时间之后，研究员发现，对于该任务而言，标注“人没有被车遮挡住的部分”的效果会远好于之前的标注，然而数据的重新标注所需要的时间是很长的，在这样的情况下，我们应当如何利用旧标签与新标签极强的相关性，去更快速的训练一个满足新标签的模型？
    \item 在真实场合下的推荐系统里，用户的喜好是不断变化的，换言之，新数据相对旧数据而言更有价值。但是，如果仅仅使用新数据，可能会由于样本量过小，以致于难以通过模型得到准确的推荐信息。在这种情况下，如何利用数据不断变化，但变化程度随时间而言幅度较小的特性，进而推断出用户所感兴趣的内容？
\end{itemize}

\subsection{任务意义}
\begin{itemize}
    \item 通过在确定正确的数据集上施加定量影响的方式，来定量研究不同的影响程度对学习准确率的影响。进而定量探究数据质量对模型表现的影响。
    \item 寻求一种利用旧的或不准确标注的数据来提高在准确标注上训练网络的收敛速度或最终结果的方法，从而得到一种更好的训练推荐系统的方式。
\end{itemize}

\subsection{任务描述}
首先，会按照数据与最终数据的相似程度，将其分为n+2个stage(编号0~n+1)。其中第0个stage与最终数据相似程度最低，相似程度随编号增加而提高，第n+1个stage即为最终数据集。之后，将会完成以下两个任务。（数据集处理的具体方法见第二部分。）

\textbf{任务一：}

在中间n个stage的数据上训练n个神经网络，并将第i个stage的数据训练所得到的网络在相邻的stage(即stage(i-1)和stage (i+1))上进行测试，\textbf{以检测各种训练数据与测试数据的差别对正确率的影响。}

注：之所以不使用前n+1个stage分别训练并在最后一个stage测试，是因为直观上最终正确率将必然呈递减趋势，我们所需要的数据为不同stage间的差异，故采用相邻stage训练/测试的方式来专注于观测这种差异。

\textbf{优化目标：本任务为实验型任务，没有优化}

\textbf{任务二：}

该任务将首先训练两个模型，

A模型：在预训练阶段，可以无限获取前n+1个stage的全部数据，且在正式训练时可以获取n+2个stage的全部数据。

B模型：不经过预训练，正式训练时仅可以获取第n+1个stage的数据。

该任务的内容为：\textbf{得出一个策略$\alpha*$,使得该策略下，经过预训练的A模型，可以通过相同的迭代次数，得到超过B模型的表现。}

\textbf{优化目标：A模型在最后一个stage下的正确率及正式训练的收敛速度}

我们的任务将采用准确度较高，可以定量施加影响的数据集。在此基础上，对数据施加定量的影响，从而进行研究。
该任务将以Classification和Regression分成两个任务进行。（施加影响的方式参见第二部分“数据集”。）

\section{数据集}

\subsection{Regression}
这部分数据集我们将采用定长定随机序列。

Initial Label:数据的40\%分位数。

Final Label:数据的60\%分位数。

之后，数据将被分为n+2个Stage，同样的，设数据大小为m，则每个Stage的数据规模为$\frac{m}{n+2}$。每个Stage对应的label如下：

Stage 0: Initial Label。

Stage 1: $40+20\times \frac{1}{n+1}$分位数。

Stage 2: $40+20 \times \frac{2}{n+1}$分位数。

Stage 3: $40+20 \times \frac{3}{n+1}$分位数。

...

Stage n: $40+20 \times \frac{n}{n+1}$分位数。

Stage n+1: Final Label.

Test Set: Final Label.

\subsection{Classification}
这部分我们将采用经典的MNIST数据集，并对数据集进行如下的划分：

首先，对label进行如下的定义：

Initial Label:初始label

Final Label:初始label xor 1之后得到的结果。(如对于每个原先标注为5的数据，在新标签里将被标注为4。)

之后，我们会将训练数据分为(n+2)个stage，每个Stage均包含有$\frac{60000}{n+2}$张图片，之后对label进行以下的改动（数据不做改变），而对于测试集，将采用原先MNIST的大小为10000的测试集，但是会对label进行对应的处理:

Stage 0: $\frac{n+1}{n+1}$ Initial Label, $\frac{0}{n+1}$ Final Label.

Stage 1: $\frac{n}{n+1}$ Initial Label, $\frac{1}{n+1}$ Final Label.

Stage 2: $\frac{n-1}{n+1}$ Initial Label, $\frac{2}{n+1}$ Final Label.

...

Stage (n-1): $\frac{2}{n+1}$ Initial Label, $\frac{n-1}{n+1}$ Final Label.

Stage n: $\frac{1}{n+1}$ Initial Label, $\frac{n}{n+1}$ Final Label.

Stage n+1: $\frac{0}{n+1}$ Initial Label, $\frac{n+1}{n+1}$ Final Label.

Test Set: $\frac{n+1}{n+1}$ Final Label.

其中A模型可以预先在Stage 0 至 Stage (n+1)的数据上进行训练，而B模型仅能在Stage n+1的数据上进行训练

\section{挑战和基线}

\subsection{挑战}

我们认为，挑战主要有以下几个方面：

\begin{itemize}
    \item 我们能否找到能够优化表现的训练策略？
    \item 不同的模型是否会需要不同的优化策略，如果是的话，寻找多个策略所需要的时间成本是否可以接受？
    \item 在真实的应用里，数据的质量往往是无法被定量刻画的，那么我们的策略能否提升模型在难以定量刻画影响的真实数据上的表现？
\end{itemize}

\subsection{基线}

任务一为实验型任务，作为任务二的基础，其重点在于研究label的错误标注的影响，故该任务不需要相应的Baseline。
任务二为策略型任务，考虑这样一个策略：A模型不进行预训练，且最终训练仅采用最后一个stage，则此时AB两模型完全相同，结果应当等价。故我们应能够找到一个更优的数据分配策略使A优于B。

我们研究效果的评估也应该分成两个部分：

基本部分：我们能否做到更快的收敛，收敛的提速情况如何？

扩展部分：我们能否通过一些方式，来利用数据在时间连续的特点，达到提高模型的准确率的目的？

\subsection{结果评价}
结果的评价应当分为两个部分：
\begin{itemize}
    \item 基本部分：A模型在达到B模型同等正确率前提下正式训练的收敛速度。
    \item 扩展部分：A模型在正式训练的最终正确率。
\end{itemize}

\section{研究计划}

\subsection{时间安排}

第九周：完成Project Proposal

第十周：完成数据集的生成和数据集参数的选取。

第十一周：部分完成任务描述中的任务一，并对数据集进行可能的调整，使之可以用于完成后续的任务。并在此外提交项目所要求的Milestone Report。

第十二周：完成任务描述中的任务一。

第十三至十四周：完成任务描述中的任务二。

第十五至十六周：将结果在真实的数据集中进行测试。

\section{可行性分析}

任务一为实验型任务，必然可行。

任务二为探究型任务，最坏情况下我们可能会得出前n+1个stage完全没有作用的结论，其余情况我们均能找出一种方案提升收敛速度或最终结果，故可行。

\section*{参考文献}


\medskip

\small

[1] Alexander, J.A.\ \& Mozer, M.C.\ (1995) Template-based algorithms
for connectionist rule extraction. In G.\ Tesauro, D.S.\ Touretzky and
T.K.\ Leen (eds.), {\it Advances in Neural Information Processing
  Systems 7}, pp.\ 609--616. Cambridge, MA: MIT Press.

[2] Bower, J.M.\ \& Beeman, D.\ (1995) {\it The Book of GENESIS:
  Exploring Realistic Neural Models with the GEneral NEural SImulation
  System.}  New York: TELOS/Springer--Verlag.

[3] Hasselmo, M.E., Schnell, E.\ \& Barkai, E.\ (1995) Dynamics of
learning and recall at excitatory recurrent synapses and cholinergic
modulation in rat hippocampal region CA3. {\it Journal of
  Neuroscience} {\bf 15}(7):5249-5262.

\end{document}

\end{CJK*}
